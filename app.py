import os
import asyncio
import logging
import io
from contextlib import redirect_stderr, redirect_stdout
from dotenv import load_dotenv
import streamlit as st
from agents import Runner

from my_agents.orchestrator_agent import orchestrator_agent
from utils.db import HOTEL_ROOMS, RESTAURANT_MENU

load_dotenv()

st.set_page_config(
    page_title="Ø³Ø§Ù…Ø§Ù†Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ØªÙ„",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state for logs and display options
if "agent_logs" not in st.session_state:
    st.session_state["agent_logs"] = []

# Initialize session state for RunResult display mode
if "show_full_runresult" not in st.session_state:
    st.session_state["show_full_runresult"] = False

# Create main layout with columns
col1, col2 = st.columns([2, 1])

with col1:
    st.title("Ø³Ø§Ù…Ø§Ù†Ù‡ Ù…Ø¯ÛŒØ±ÛŒØª Ù‡ØªÙ„")
    st.caption("Ú¯ÙØªÚ¯Ùˆ Ø¨Ø±Ø§ÛŒ Ø±Ø²Ø±Ùˆ Ø§ØªØ§Ù‚ Ùˆ Ø³ÙØ§Ø±Ø´ ØºØ°Ø§")

with col2:
    st.header("ğŸ“Š ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ Ø³ÛŒØ³ØªÙ…")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

with st.sidebar:
    st.header("Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª")

    if st.button("ğŸ”„ Ø´Ø±ÙˆØ¹ Ú¯ÙØªÚ¯ÙˆÛŒ Ø¬Ø¯ÛŒØ¯", type="primary"):
        st.session_state["messages"] = []
        st.session_state["agent_logs"] = []
        st.session_state.pop("prefill", None)
        st.rerun()

    # Response display options
    st.divider()
    st.subheader(" ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù†Ù…Ø§ÛŒØ´")

# Add database status to the right column
with col2:
    # Room status with colors
    with st.expander("ğŸ¨ ÙˆØ¶Ø¹ÛŒØª Ø§ØªØ§Ù‚â€ŒÙ‡Ø§", expanded=True):
        for room in HOTEL_ROOMS:
            room_type_fa = {
                'single': 'ÛŒÚ© Ù†ÙØ±Ù‡',
                'double': 'Ø¯Ùˆ Ù†ÙØ±Ù‡', 
                'triple': 'Ø³Ù‡ Ù†ÙØ±Ù‡'
            }.get(room['type'], room['type'])
            
            if room['available']:
                st.markdown(f"ğŸŸ¢ **{room['id']}** ({room_type_fa}) - âœ… Ø¢Ø²Ø§Ø¯ - {room['price_per_night']}$ Ø´Ø¨Ø§Ù†Ù‡")
            else:
                st.markdown(f"ğŸ”´ **{room['id']}** ({room_type_fa}) - âŒ Ø±Ø²Ø±Ùˆ Ø´Ø¯Ù‡")

    # Menu status with colors
    with st.expander("ğŸ½ï¸ ÙˆØ¶Ø¹ÛŒØª Ù…Ù†ÙˆÛŒ Ø±Ø³ØªÙˆØ±Ø§Ù†", expanded=True):
        for item in RESTAURANT_MENU:
            if item['available']:
                st.markdown(f"ğŸŸ¢ **{item['name']}** - âœ… Ù…ÙˆØ¬ÙˆØ¯ - {item['price']}$")
            else:
                st.markdown(f"ğŸ”´ **{item['name']}** - âŒ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯")

if not os.getenv("OPENAI_API_KEY"):
    st.error("Ù„Ø·ÙØ§Ù‹ Ù…Ù‚Ø¯Ø§Ø± OPENAI_API_KEY Ø±Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ .env ÛŒØ§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ… Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯.")

# Display chat messages in the left column
with col1:
    for m in st.session_state["messages"]:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

def run_agent_sync(prompt: str, conversation_history: list = None):
    """Run the orchestrator agent and capture logs."""
    async def _run():
        # Construct context with conversation history
        if conversation_history and len(conversation_history) > 1:
            context_parts = ["ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú¯ÙØªÚ¯Ùˆ:\n"]
            for i, msg in enumerate(conversation_history[:-1]):  # Exclude the current message
                role = "Ú©Ø§Ø±Ø¨Ø±" if msg["role"] == "user" else "Ø¯Ø³ØªÛŒØ§Ø±"
                context_parts.append(f"{role}: {msg['content']}")
            
            context_parts.append(f"\nÙ¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ø±Ø¨Ø±: {prompt}")
            full_context = "\n".join(context_parts)
        else:
            full_context = prompt
            
        # Log the start of processing
        st.session_state["agent_logs"].append(f"Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: {prompt[:50]}...")
        
        try:
            # Capture stdout/stderr during agent execution
            log_capture_string = io.StringIO()
            with redirect_stdout(log_capture_string), redirect_stderr(log_capture_string):
                result = await Runner.run(orchestrator_agent, full_context)
            
            # Capture any logs from the execution
            captured_logs = log_capture_string.getvalue()
            if captured_logs.strip():
                st.session_state["agent_logs"].append(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ø¬Ø±Ø§: {captured_logs.strip()}")
                
            st.session_state["agent_logs"].append("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯")
                        
            return result
            
        except Exception as e:
            error_msg = f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}"
            st.session_state["agent_logs"].append(error_msg)
            raise e
    
    return asyncio.run(_run())

# Chat interface in the left column
with col1:
    prefill = st.session_state.get("prefill", "ÛŒÚ© Ø§ØªØ§Ù‚ Ø¯Ùˆ Ù†ÙØ±Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ù‡ Ø´Ø¨ Ù…ÛŒâ€ŒØ®ÙˆØ§Ø³ØªÙ….")
    user_prompt = st.chat_input("Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯â€¦", key="chat_input")

    if user_prompt is None and "prefill" in st.session_state:
        user_prompt = st.session_state.pop("prefill")

    if user_prompt:
        response_text = ""
        st.session_state["messages"].append({"role": "user", "content": user_prompt})
        with st.chat_message("user"):
            st.markdown(user_prompt)

        with st.chat_message("assistant"):
            with st.spinner("... Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´"):
                try:
                    # Pass conversation history to maintain context
                    result = run_agent_sync(user_prompt, st.session_state["messages"])
                    response_text = str(result.final_output).strip()
                    st.markdown(response_text)
                        
                except Exception as e:
                    response_text = f"âš ï¸ Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø´Ù…Ø§ Ø±Ø® Ø¯Ø§Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.\n\nğŸ“ Ø¬Ø²Ø¦ÛŒØ§Øª Ø®Ø·Ø§: {str(e)}"
                    st.markdown(response_text)
            
        # Store the response in session state
        st.session_state["messages"].append({"role": "assistant", "content": response_text})
